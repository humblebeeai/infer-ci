{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Metrics with Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, ensure you have the required packages installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tqdm PyYAML ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "from confidenceinterval import MetricEvaluator \n",
    "from ultralytics import YOLO\n",
    "import shutil\n",
    "\n",
    "print(\"‚úì Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model and Run Predictions\n",
    "\n",
    "We'll use a pre-trained YOLOv8 model to generate predictions on the COCO128 validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv8 nano model (smallest and fastest)\n",
    "print('Loading YOLOv8n model...')\n",
    "model = YOLO('yolov8n.pt')  # Automatically downloads if not present\n",
    "print('‚úì Model loaded')\n",
    "\n",
    "model.val(data=\"coco128.yaml\", epochs=1)\n",
    "\n",
    "dataset_path = Path('coco128')\n",
    "\n",
    "# # check dataset structur\n",
    "def validate_yolo_dataset(\n",
    "    dataset_path: Path,\n",
    "    split: str = \"train2017\",\n",
    "    fix_structure: bool = False,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    dataset_path = Path(dataset_path)\n",
    "\n",
    "    issues = {\n",
    "        \"missing_labels\": [],\n",
    "        \"missing_images\": [],\n",
    "        \"extra_labels\": [],\n",
    "        \"extra_images\": [],\n",
    "        \"structure_errors\": [],\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"YOLO DATASET VALIDATION\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Dataset path: {dataset_path}\")\n",
    "        print(f\"Split: {split}\")\n",
    "\n",
    "    if not dataset_path.exists():\n",
    "        issues[\"structure_errors\"].append(f\"Dataset directory not found: {dataset_path}\")\n",
    "        return False, issues\n",
    "\n",
    "    images_root = dataset_path / \"images\"\n",
    "    labels_root = dataset_path / \"labels\"\n",
    "    images_split = images_root / split\n",
    "    labels_split = labels_root / split\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # üîß FIX: Move files UP from split folder to root\n",
    "    # --------------------------------------------------\n",
    "    if fix_structure:\n",
    "        if images_split.exists():\n",
    "            images_root.mkdir(exist_ok=True, parents=True)\n",
    "            moved = 0\n",
    "            for img in images_split.iterdir():\n",
    "                if img.is_file():\n",
    "                    shutil.move(str(img), str(images_root / img.name))\n",
    "                    moved += 1\n",
    "            if verbose:\n",
    "                print(f\"üîß Moved {moved} images from {images_split} ‚Üí {images_root}\")\n",
    "            if not any(images_split.iterdir()):\n",
    "                images_split.rmdir()\n",
    "\n",
    "        if labels_split.exists():\n",
    "            labels_root.mkdir(exist_ok=True, parents=True)\n",
    "            moved = 0\n",
    "            for lbl in labels_split.glob(\"*.txt\"):\n",
    "                if lbl.is_file():\n",
    "                    shutil.move(str(lbl), str(labels_root / lbl.name))\n",
    "                    moved += 1\n",
    "            if verbose:\n",
    "                print(f\"üîß Moved {moved} labels from {labels_split} ‚Üí {labels_root}\")\n",
    "            if not any(labels_split.iterdir()):\n",
    "                labels_split.rmdir()\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Validate final structure\n",
    "    # --------------------------------------------------\n",
    "    if not images_root.exists():\n",
    "        issues[\"structure_errors\"].append(f\"Images directory not found: {images_root}\")\n",
    "        return False, issues\n",
    "\n",
    "    if not labels_root.exists():\n",
    "        issues[\"structure_errors\"].append(f\"Labels directory not found: {labels_root}\")\n",
    "        return False, issues\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n‚úì Directory structure:\")\n",
    "        print(f\"  Images: {images_root}\")\n",
    "        print(f\"  Labels: {labels_root}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Collect files\n",
    "    # --------------------------------------------------\n",
    "    image_exts = [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"]\n",
    "    image_files = {}\n",
    "\n",
    "    for ext in image_exts:\n",
    "        for img in images_root.glob(f\"*{ext}\"):\n",
    "            image_files[img.stem] = img\n",
    "        for img in images_root.glob(f\"*{ext.upper()}\"):\n",
    "            image_files[img.stem] = img\n",
    "\n",
    "    label_files = {lbl.stem: lbl for lbl in labels_root.glob(\"*.txt\")}\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nüìä Dataset Statistics:\")\n",
    "        print(f\"  Total images: {len(image_files)}\")\n",
    "        print(f\"  Total labels: {len(label_files)}\")\n",
    "\n",
    "    image_stems = set(image_files)\n",
    "    label_stems = set(label_files)\n",
    "\n",
    "    missing_labels = image_stems - label_stems\n",
    "    missing_images = label_stems - image_stems\n",
    "\n",
    "    issues[\"missing_labels\"] = sorted(missing_labels)\n",
    "    issues[\"missing_images\"] = sorted(missing_images)\n",
    "\n",
    "    matched = len(image_stems & label_stems)\n",
    "    is_valid = matched > 0 and not issues[\"structure_errors\"]\n",
    "\n",
    "    if verbose:\n",
    "        if missing_labels:\n",
    "            print(f\"\\n‚ö†Ô∏è Images without labels: {len(missing_labels)}\")\n",
    "            for stem in sorted(list(missing_labels))[:10]:\n",
    "                print(f\"   - {stem}\")\n",
    "\n",
    "        if missing_images:\n",
    "            print(f\"\\n‚ö†Ô∏è Labels without images: {len(missing_images)}\")\n",
    "            for stem in sorted(list(missing_images))[:10]:\n",
    "                print(f\"   - {stem}.txt\")\n",
    "                \n",
    "    if verbose:\n",
    "        print(f\"\\n{'‚úì' if is_valid else '‚ùå'} Matched pairs: {matched}\")\n",
    "\n",
    "    return is_valid, issues\n",
    "\n",
    "validate_yolo_dataset(dataset_path, split='train2017', fix_structure=True, verbose=True)\n",
    "\n",
    "# Run predictions on COCO128 validation images\n",
    "print('\\nRunning predictions on COCO128...')\n",
    "print('=' * 50)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = model.predict(\n",
    "    source=dataset_path / 'images' / 'train2017',  # Validation images\n",
    "    imgsz=640,\n",
    "    conf=0.25,  # Confidence threshold\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"‚úì Predictions completed in {elapsed:.2f}s\")\n",
    "print(f\"  - Predicted on {len(results)} images\")\n",
    "print(f\"  - Average: {elapsed/len(results)*1000:.1f}ms per image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute mAP@0.5:0.95 with Confidence Interval\n",
    "\n",
    "Now we'll compute the mean Average Precision with a 95% confidence interval using bootstrap resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image not found for label 000000000656.txt, using default shape (640, 640)\n",
      "Image not found for label 000000000659.txt, using default shape (640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Metric evaluator initialized\n",
      "\n",
      "Computing mAP@0.5:0.95 with 95% CI...\n",
      "==================================================\n",
      "  ‚ö†Ô∏è  Skipped 2 predictions without matching ground truth labels:\n",
      "     - 000000000250.txt (label file not found)\n",
      "     - 000000000508.txt (label file not found)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap CI:   3%|‚ñé         | 3/100 [00:00<00:04]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap CI: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram plot saved to: results/mAP@0.5:0.95_bootstrap_percentile_20251222_134358.png\n",
      "\n",
      "==================================================\n",
      "RESULTS\n",
      "==================================================\n",
      "mAP@0.5:0.95: 0.4916\n",
      "95% CI: [0.4389, 0.5357]\n",
      "CI width: 0.0967\n",
      "\n",
      "‚úì Histogram plot saved to results/ directory\n"
     ]
    }
   ],
   "source": [
    "# Initialize the metric evaluator\n",
    "evaluate = MetricEvaluator()\n",
    "print(\"‚úì Metric evaluator initialized\")\n",
    "\n",
    "# Compute mAP@0.5:0.95 with confidence interval\n",
    "print('\\nComputing mAP@0.5:0.95 with 95% CI...')\n",
    "print('=' * 50)\n",
    "\n",
    "map_value, (lower, upper) = evaluate.evaluate(\n",
    "    y_true=str(dataset_path),  # Dataset root directory\n",
    "    y_pred=results,             # prediction results\n",
    "    task='detection',\n",
    "    metric='map',           # available: 'map', 'precision', 'recall'\n",
    "    method='bootstrap_percentile', # default method 'bootstrap_bca'\n",
    "    n_resamples=100,  # Use 100 for speed (use 1000+ for production)\n",
    "    plot=True,  # Create histogram plot\n",
    "    # plot_per_class=True, # Plot per-class distributions default: False\n",
    ")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(f\"RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"mAP@0.5:0.95: {map_value:.4f}\")\n",
    "print(f\"95% CI: [{lower:.4f}, {upper:.4f}]\")\n",
    "print(f\"CI width: {upper - lower:.4f}\")\n",
    "print(f\"\\n‚úì Histogram plot saved to results/ directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
